{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import distributions as dist\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.3 HW Problems 13-16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Write a program that performs A/B testing  Have each arm tested m times to \n",
    "estimate each (theta_1, ..., theta_n) with the MLE estimator.  Then choose\n",
    "the largest theta_i and use the remaining N - nm pulls (where N is the total \n",
    "number of pulls) to try to maximize the average payoff.  Compare average payout \n",
    "with Thompson sampling in Algorithm 17.1\n",
    "\"\"\"\n",
    "\n",
    "def ab_test(thetas, rewards, N, m):\n",
    "    n = len(thetas)\n",
    "\n",
    "    # Calculate estimated thetas using samples\n",
    "    est_thetas = np.array([np.sum(np.random.binomial(1, theta, m)) / m for theta in thetas])\n",
    "\n",
    "    # Calculate expected values\n",
    "    expected_vals = est_thetas * rewards\n",
    "    max_index = np.argmax(expected_vals)\n",
    "    if type(max_index) is np.ndarray:\n",
    "        max_index = max_index[0]\n",
    "\n",
    "    # Find and return best payout\n",
    "    payout = np.sum(np.random.binomial(1, est_thetas[max_index], N - n*m)) * rewards[max_index] / N\n",
    "    return payout\n",
    "\n",
    "\n",
    "def thompson_sampling(theta, rewards, N):\n",
    "    \"\"\"\n",
    "    Thompson sample to choose the arm, then simulate a pull, then update.  Repeat\n",
    "    N times.\n",
    "\n",
    "    theta : array of true probabilities for the arms\n",
    "    N     : total number of pulls to make\n",
    "\n",
    "    Return percentage of successes up to each time step\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize\n",
    "    n = len(theta)      # Number of arms\n",
    "    a = np.ones(n)      # Initial 'a' hyperparameters\n",
    "    b = np.ones(n)      # Initial 'b' hyperparameters\n",
    "    X = np.random.random(N) # Draw from [0,1] to simulate pulls\n",
    "    traj = np.zeros(N)      # Initial trajectory\n",
    "\n",
    "    for k in range(N):\n",
    "        draw = dist.beta.rvs(a,b)   # Thompson sample for all arms\n",
    "        index = np.argmax(draw * rewards)     # Identify arm to pull\n",
    "        if X[k] <= theta[index]:    # If pull is a success\n",
    "            a[index] += 1   # Update posterior with success\n",
    "            traj[k] = traj[k-1] + 1 # Update trajectory\n",
    "        else:\n",
    "            b[index] += 1           # Update posterior with failure\n",
    "            traj[k] = traj[k-1]         # Update trajectory\n",
    "    return traj / np.arange(1, N+1)     # Percentage successes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A/B Testing average payout over 500 runs: 0.26539999999999997\n",
      "Thompson Sampling average payout over 500 runs: 0.38567999999999997\n"
     ]
    }
   ],
   "source": [
    "thetas = np.array([0.3, 0.45, 0.23, 0.4])\n",
    "rewards = np.array([1, 1, 1, 1])\n",
    "N = 100\n",
    "m = 12\n",
    "\n",
    "print(f'A/B Testing average payout over 500 runs: {np.mean(np.array([ab_test(thetas, rewards, N, m) for _ in range(500)]))}')\n",
    "print(f'Thompson Sampling average payout over 500 runs: {np.mean(np.array([thompson_sampling(thetas, rewards, N)[-1] for _ in range(500)]))}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "As an alternative to A/B testing, try randomly choosing arms (with replacement) \n",
    "m times and give MLE estimates for each (theta_1,..., theta_n). Then choose\n",
    "the largest theta_i and use the remaining N - m pulls to try to maximize the\n",
    "average payoff.  Compare average payoff with A/B testing and Thompson sampling.\n",
    "\"\"\"\n",
    "\n",
    "def random_test(thetas, rewards, N, m):\n",
    "    n = len(thetas)\n",
    "\n",
    "    # Compute random m values to sample for each theta\n",
    "    m_vals = [1] * n\n",
    "    for _ in range(m - n):\n",
    "        index = random.randint(0, n-1)\n",
    "        m_vals[index] += 1\n",
    "\n",
    "    # Calculate estimated thetas using samples\n",
    "    for m_val in m_vals:\n",
    "        est_thetas = np.array([np.sum(np.random.binomial(1, theta, m_val)) / m_val for theta in thetas])\n",
    "\n",
    "    # Calculate expected values\n",
    "    expected_vals = est_thetas * rewards\n",
    "    max_index = np.argmax(expected_vals)\n",
    "    if type(max_index) is np.ndarray:\n",
    "        max_index = max_index[0]\n",
    "\n",
    "    # Find and return best payout\n",
    "    payout = np.sum(np.random.binomial(1, est_thetas[max_index], N - n*m)) * rewards[max_index] / N\n",
    "    return payout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Testing average payout over 500 runs: 0.35094\n",
      "A/B Testing average payout over 500 runs: 0.27244000000000007\n",
      "Thompson Sampling average payout over 500 runs: 0.37874\n"
     ]
    }
   ],
   "source": [
    "thetas = np.array([0.3, 0.45, 0.23, 0.4])\n",
    "rewards = np.array([1, 1, 1, 1])\n",
    "N = 100\n",
    "m = 12\n",
    "\n",
    "print(f'Random Testing average payout over 500 runs: {np.mean(np.array([random_test(thetas, rewards, N, m) for _ in range(500)]))}')\n",
    "print(f'A/B Testing average payout over 500 runs: {np.mean(np.array([ab_test(thetas, rewards, N, m) for _ in range(500)]))}')\n",
    "print(f'Thompson Sampling average payout over 500 runs: {np.mean(np.array([thompson_sampling(thetas, rewards, N)[-1] for _ in range(500)]))}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Instead of evaluating algorithms based on average payout over time, reapply\n",
    "A/B testing and Thompson sampling but assess the quality with the discounted\n",
    "utility function sum(B^i * u_i), where u_i is the payoff.  By doing multple\n",
    "runs, compute the expected utility and use that as the basis of comparison\n",
    "for deciding whether Thompson sampling is better than A/B testing\n",
    "\"\"\"\n",
    "\n",
    "def ab_test_discounted(thetas, rewards, N, m, betas):\n",
    "    n = len(thetas)\n",
    "\n",
    "    # Calculate estimated thetas using samples\n",
    "    est_thetas = np.array([np.sum(np.random.binomial(1, theta, m)) / m for theta in thetas])\n",
    "\n",
    "    # Calculate expected values\n",
    "    expected_vals = est_thetas * rewards\n",
    "    max_index = np.argmax(expected_vals)\n",
    "    if type(max_index) is np.ndarray:\n",
    "        max_index = max_index[0]\n",
    "\n",
    "    # Find and return best payout\n",
    "    discounted_utility = np.sum(np.random.binomial(1, est_thetas[max_index], N - n*m) * rewards[max_index] * betas)\n",
    "    return discounted_utility\n",
    "\n",
    "def thompson_sampling_discounted(theta, rewards, N, betas):\n",
    "    \"\"\"\n",
    "    Thompson sample to choose the arm, then simulate a pull, then update.  Repeat\n",
    "    N times.\n",
    "\n",
    "    theta : array of true probabilities for the arms\n",
    "    N     : total number of pulls to make\n",
    "\n",
    "    Return percentage of successes up to each time step\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize\n",
    "    n = len(theta)      # Number of arms\n",
    "    a = np.ones(n)      # Initial 'a' hyperparameters\n",
    "    b = np.ones(n)      # Initial 'b' hyperparameters\n",
    "    X = np.random.random(N) # Draw from [0,1] to simulate pulls\n",
    "    traj = np.zeros(N)      # Initial trajectory\n",
    "\n",
    "    for k in range(N):\n",
    "        draw = dist.beta.rvs(a,b)   # Thompson sample for all arms\n",
    "        index = np.argmax(draw * rewards)     # Identify arm to pull\n",
    "        if X[k] <= theta[index]:    # If pull is a success\n",
    "            a[index] += 1   # Update posterior with success\n",
    "            traj[k] = traj[k-1] + 1 # Update trajectory\n",
    "        else:\n",
    "            b[index] += 1           # Update posterior with failure\n",
    "            traj[k] = traj[k-1]         # Update trajectory\n",
    "    return np.sum(traj / np.arange(1, N+1) * betas)     # Percentage successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A/B Discounted Utility: 12.196078431372548\n",
      "Thompson Sampling Discounted Utility: 15.879353952603227\n"
     ]
    }
   ],
   "source": [
    "thetas = np.array([0.3, 0.45, 0.23, 0.4])\n",
    "rewards = np.array([1, 1, 1, 1])\n",
    "N = 100\n",
    "m = 12\n",
    "n = len(thetas)\n",
    "domain = np.linspace(0, 1, N - m*n)\n",
    "domain_thompson = np.linspace(0, 1, N)\n",
    "betas = np.array([-domain + 1])\n",
    "betas_thompson = np.array([-domain_thompson + 1])\n",
    "\n",
    "print(f'A/B Discounted Utility: {ab_test_discounted(thetas, rewards, N, m, betas)}')\n",
    "print(f'Thompson Sampling Discounted Utility: {thompson_sampling_discounted(thetas, rewards, N, betas_thompson)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generalize Algorithm 17.1 by coding up a simulation of a Bernoulli bandit \n",
    "process/solution where Thompson sampling can also accommodate an array of\n",
    "payouts (J_1,..., J_n) for each arm\n",
    "\"\"\"\n",
    "\n",
    "def thompson_sampling_rewards(theta, rewards, N):\n",
    "    \"\"\"\n",
    "    Thompson sample to choose the arm, then simulate a pull, then update.  Repeat\n",
    "    N times.\n",
    "\n",
    "    theta : array of true probabilities for the arms\n",
    "    N     : total number of pulls to make\n",
    "\n",
    "    Return percentage of successes up to each time step\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize\n",
    "    n = len(theta)      # Number of arms\n",
    "    a = np.ones(n)      # Initial 'a' hyperparameters\n",
    "    b = np.ones(n)      # Initial 'b' hyperparameters\n",
    "    X = np.random.random(N) # Draw from [0,1] to simulate pulls\n",
    "    traj = np.zeros(N)      # Initial trajectory\n",
    "\n",
    "    for k in range(N):\n",
    "        draw = dist.beta.rvs(a,b)   # Thompson sample for all arms\n",
    "        index = np.argmax(draw * rewards)     # Identify arm to pull accounting for rewards\n",
    "        if X[k] <= theta[index]:    # If pull is a success\n",
    "            a[index] += 1   # Update posterior with success\n",
    "            traj[k] = traj[k-1] + 1 # Update trajectory\n",
    "        else:\n",
    "            b[index] += 1           # Update posterior with failure\n",
    "            traj[k] = traj[k-1]         # Update trajectory\n",
    "    return (traj / np.arange(1, N+1))[-1]     # Percentage successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thompson Sampling Accounting for Rewards: 0.45\n"
     ]
    }
   ],
   "source": [
    "thetas = np.array([0.3, 0.45, 0.23, 0.4])\n",
    "rewards = np.array([1, 2, 3, 4])\n",
    "N = 100\n",
    "m = 12\n",
    "n = len(thetas)\n",
    "\n",
    "print(f'Thompson Sampling Accounting for Rewards: {thompson_sampling_rewards(thetas, rewards, N)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
